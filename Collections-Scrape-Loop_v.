from bs4 import BeautifulSoup
import requests
import lxml
import time


i = 1
while (i < 4000):
    page = requests.get("https://archiveofourown.org/collections?page=" + str(i) + "&sort_column=collections.created_at&sort_direction=DESC")
    page_html = BeautifulSoup(page.content, "lxml")
    
    works = page_html.find_all("li", {"role" : "article"})

    print(i)

    for work in works:
        if work.find("h4", { "class" : "heading" }) is not None:
            header = work.find("h4", { "class" : "heading" })
            collection = header.select_one("a")
            user_e = collection.next_element.next_element
            user_e1 = user_e.next_element.next_element
            user_e2 = user_e1.next_element.next_element
            user = user_e2["href"]
            user_link =user.replace("/users", "https://archiveofourown.org/users")
        
            user_page = requests.get(user_link)
            user_page_html = BeautifulSoup(user_page.content, "lxml")
            navigation = user_page_html.find("ul", {"class" : "navigation actions"})
            dashboard = navigation.select_one("a")
            user_prof_base = dashboard["href"] 
            profile_link = user_prof_base.replace("/users" , "https://archiveofourown.org/users")
            print("Profile link: " + profile_link)

            profiles = requests.get(profile_link)
            profile_html = BeautifulSoup(profiles.content, "lxml")
            home_profile = profile_html.find("div", {"class" : "user home profile"})
            email_identifier = home_profile.find("dt", {"class" : "email"})
            
            if email_identifier is not None:
                email_location = home_profile.find("dd", {"class" : "email"})
                email = email_location.text
                print(email)    
                
            sleep(1)
            
    i += 1  
